{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progresso 4/12/23:\n",
    "\n",
    "#### Avancei nas atividades:\n",
    "* Estudei o pipeline historical do site-location-Jet-Oil.\n",
    "\n",
    "* Rodei os exemplos da ferramenta Feast (feature store) e estudei as classes que são utilizadas.\n",
    "#### Conquistas do Dia:\n",
    "\n",
    "* Comecei a montar o meu mapa do pipeline que já estudei do Jet-Oil.\n",
    "* Comecei a documentar como se cria a Loja de Features.\n",
    "#### Desafios Enfrentados:\n",
    "\n",
    "* Falta de acesso ao Jira e Confluence.\n",
    "#### Próximos Passos:\n",
    "\n",
    "* Investigar todas as funções do pipeline historical.\n",
    "* Docummentar a utilização das classes do Feature Store FEAST.\n",
    "#### Expectativas para o Próximo Dia:\n",
    "\n",
    "* Tô confiante de que vou estar com quase todas as funções investigadas pra amanhã e card finalizado para 6/13.\n",
    "* Ao passo que receber o acesso e terminar de documentar o progresso na task do FEAST, completar o card no Jira.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progresso 5/12/23:\n",
    "\n",
    "#### Atividades:\n",
    "\n",
    "* Estudei databricks e Feast de manhã\n",
    "\n",
    "* De tarde terminei de testar as funcionalidades do Feast.\n",
    "\n",
    "* Me reuni com o Daniel e ele me explicou umas regras e me disse pra começar a estudar\n",
    "\n",
    "    o pipeline Historical do Faturamento pois é a parte ETL do pipeline. \n",
    "    \n",
    "    Ficou marcado pra segunda me reunir com ele pra ele mo mostrar o código mais a fundo.\n",
    "#### Conquistas do Dia:\n",
    "\n",
    "* Rodei todas as funções da loja de features com a biblioteca Feast.\n",
    "* Implementei um notebook com as principais funcionalidades da biblioteca, para passar para o confluence assim que tiver acesso.\n",
    " \n",
    "#### Desafios Enfrentados:\n",
    "\n",
    "* Tive problemas em entender como não estragar o feature store, colocando programas na pasta ele deixava de funcionar.\n",
    "    \n",
    "    Solucionei deixando os programas de fora e acessando a Loja através do caminho.\n",
    "\n",
    "* Não tenho acesso ao Gira e ao Confluence.\n",
    "\n",
    "#### Próximos Passos:\n",
    "\n",
    "* Descrever os códigos usados pra rodar o FEAST, completando o card. (quase pronto)\n",
    "\n",
    "* Estudar o fluxo dos dados realizados pelo pipeline Historical, que usa a função 'generate_faturamento_franquias'\n",
    "#### Expectativas para o Próximo Dia:\n",
    "\n",
    "* Terminar a documentação da task do Feast de manhã.\n",
    "\n",
    "* Começar a estudar o pipeline de manhã também.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progresso 6/12/23:\n",
    "\n",
    "#### Atividades:\n",
    "\n",
    "* Entregar a task do Feast\n",
    "\n",
    "* Estudar o pipeline do faturamento historical\n",
    "\n",
    "\n",
    "#### Conquistas do Dia:\n",
    "\n",
    "* Terminei o notebook com as funções do FEAST. Escrevi os DoD's da card do Jira e faltou somente a precificação da SDK FEAST.\n",
    "\n",
    "* Com o Matheus, observei e dei pitaco na documentação do contexto databricks na AzureML. Aprendi bastante e ficou tudo mais claro.\n",
    "\n",
    "* Acompanhanhei o Matheus na criação da documentação do contexto_databricks do Projetaai para realizar a autenticação no ambiente AzureML.\n",
    "\n",
    " \n",
    "#### Desafios Enfrentados:\n",
    "\n",
    "* Atrasei a task de estudar o pipeline, logo que acabei de estudar o Feast Entrei em call com o Matheus.\n",
    "\n",
    "    Porém aprendi sobre como o Projetaai, utiliza Contexto_databricks.py para gerenciar as chaves e tokens para utilizar o AzureML.\n",
    "    \n",
    "    __Ainda não consigo rodar/entender toda a estrutura__, porém hoje vimos tudo.\n",
    "\n",
    "* Não tive tempo de estudar o pipeline até agora as 17:25, vou ter que começar amanhã de manhã a ler os códigos.\n",
    "\n",
    "#### Próximos Passos:\n",
    "\n",
    "* Atualizar o card no Gira com a apresentação referente a Task do FEAST.\n",
    "\n",
    "* Estudar a parte ETL do pipeline faturamento histórical.\n",
    "\n",
    "* Usar essa documentação do Matheus para testar, lendo alguma base (pedindo ajuda a Nívea se for necessário).\n",
    "\n",
    "#### Expectativas para o Próximo Dia:\n",
    "\n",
    "* Ter Dúvidas sobre o pipeline ETL para perguntar ao Daniel.\n",
    "\n",
    "* Ter os acessos que faltam (portal Azure, Confluence).\n",
    "\n",
    "* Testar a documentação do Matheus tentando fazer as conexões e lendo alguma base."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progresso 7/12/23:\n",
    "\n",
    "#### Atividades:\n",
    "\n",
    "* Atualizei a card do Feature Store (FS) com o notebook de resumo. \n",
    "\n",
    "* Trabalhei na apresentação do FS, vou aprensetar os dados de Iris-flower.\n",
    "\n",
    "* Estudei a documentação do CookieCutter que o Matheus me passou.\n",
    "\n",
    "* Estudei o pipeline do faturamento historical, foi difícil.\n",
    "\n",
    "\n",
    "#### Conquistas do Dia:\n",
    "\n",
    "* Criei e adicionei apenas dois, dos quatro, features num FS. A ideia é inserir os outros dois features no banco e obter os dados de \n",
    "\n",
    "treino com os quatro features, mostrando todas as capacidades do FEAST.\n",
    "\n",
    "* Terminei o notebook com as funções do FEAST. Escrevi os DoD's da card do Jira e faltou somente a precificação da SDK FEAST.\n",
    "\n",
    "* Ao passo que estudava as funções do pipeline, eu investigava também como fazer em Pyspark. \n",
    "\n",
    " \n",
    "#### Desafios Enfrentados:\n",
    "\n",
    "* Foi dito pra tentar reproduzir o que está na documentação do Contexto Databricks, porém sigo sem acesso ao Confluence.\n",
    "\n",
    "\n",
    "\n",
    "#### Próximos Passos:\n",
    "\n",
    "* Continuar a estudar a parte ETL do pipeline faturamento histórical.\n",
    "\n",
    "* Usar essa documentação do Matheus para testar, lendo alguma base (pedindo ajuda a Nívea se for necessário).\n",
    "\n",
    "* Testar a documentação do Cookie cutter.\n",
    "\n",
    "#### Expectativas para o Próximo Dia:\n",
    "\n",
    "* Obter sucesso na utilização da documentação para rodar o CookieCutter e/ou Databricks_context.\n",
    "\n",
    "* Ter os acessos que faltam (portal Azure, Confluence).\n",
    "\n",
    "* Falar com o Daniel e expor alguma dúvida bem fundamentada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progresso 8/12/23:\n",
    "\n",
    "#### Atividades:\n",
    "\n",
    "* Estudei toda a documentação do Databricks_connect, entendi bem, e logo terei domínio de todo código da Infraestrutura.\n",
    "* Investiguei a função 'generate_faturamento_franquias' do pipeline historical.\n",
    "* Estudei a Documentação do CookieCutter.\n",
    "\n",
    "#### Conquistas do Dia:\n",
    "\n",
    "* Relembrei como ler as bases e compreendi melhor a infraestrutura em termos de conexões, credenciais, KeyVaults, etc.\n",
    "* Sobre o site_location_jetoil, eu criei o ambiente, realizei testes e fiquei impedido de avançar por falta de acesso ao AML.\n",
    "* Entendi que o cookie cutter serve para criar bibliotecas e fiz parte dos processos da documentação.\n",
    "\n",
    " \n",
    "#### Desafios Enfrentados:\n",
    "\n",
    "* Faltas de acessos ao AML é um problema, pois limita as linhas de raciocínios e impede testes.\n",
    "\n",
    "#### Próximos Passos:\n",
    "\n",
    "* Entender a documentação do coockie cutter completamente.\n",
    "* Ler alguma base com Databricks.\n",
    "* Realizar o refactor pra primeira função 'generate_faturamento_franquias'.\n",
    "* Arrumar a Card do Jira, quando fiz o Clone do card Da Nivea ele virou uma issue, e não soube desfazer.\n",
    "\n",
    "#### Expectativas para o Próximo Dia:\n",
    "\n",
    "* Completar a documentação (contexto databricks) com as sugestões que realizei no Card do Jira\n",
    "* Obter o ppt do P&D do FEAST.\n",
    "* Começar o refactor para Pyspark com 'kedro Jupyter lab'.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progresso 9/12/23:\n",
    "\n",
    "#### Atividades:\n",
    "\n",
    "* Estudei as leis de Lehman\n",
    "* Verifiquei os acessos ao Azure ML e fiz um Tour de como rodar os pipelines.\n",
    "* Participei da Dinâmica da retrospectiva.\n",
    "\n",
    "\n",
    "#### Conquistas do Dia:\n",
    "\n",
    "* Ajudei a criar um slide do site_location_JetOil no ppt da retrospectiva 2023.(ainda incompleto)\n",
    "* Organizei uma imagem das leis de Lehman\n",
    "![Screenshot from 2023-12-11 14-00-45.png](<attachment:Screenshot from 2023-12-11 14-00-45.png>)\n",
    "\n",
    " \n",
    "#### Desafios Enfrentados:\n",
    "\n",
    "* Faltas de acessos ao AML é um problema, pois limita as linhas de raciocínios e impede testes.\n",
    "\n",
    "#### Próximos Passos:\n",
    "\n",
    "* Entender a documentação do coockie cutter completamente.\n",
    "* Ler alguma base com Databricks.\n",
    "* Realizar o refactor pra primeira função 'generate_faturamento_franquias'.\n",
    "* Arrumar a Card do Jira, quando fiz o Clone do card Da Nivea ele virou uma issue, e não soube desfazer.\n",
    "\n",
    "#### Expectativas para o Próximo Dia:\n",
    "\n",
    "* Completar a documentação (contexto databricks) com as sugestões que realizei no Card do Jira\n",
    "* Obter o ppt do P&D do FEAST.\n",
    "* Começar o refactor para Pyspark com 'kedro Jupyter lab'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
